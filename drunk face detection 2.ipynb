{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f95aa0de-8a91-4896-9c1a-0ab8eecb14a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import datetime\n",
    "import time\n",
    "\n",
    "# Load the pre-trained Haarcascades face classifier\n",
    "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "\n",
    "# Open the camera\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Log file for recording events\n",
    "log_file = open(\"drunk_detection_log.txt\", \"a\")\n",
    "\n",
    "# Set initial message variables\n",
    "current_message = \"Initializing...\"\n",
    "message_changed = False\n",
    "\n",
    "# Variables for analyzing the person for 5 seconds\n",
    "start_time = time.time()\n",
    "analysis_duration = 5  # seconds\n",
    "is_drunk_count = 0\n",
    "\n",
    "while True:\n",
    "    # Read a frame from the camera\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    # Convert the frame to grayscale for face detection\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Detect faces in the frame\n",
    "    faces = face_cascade.detectMultiScale(gray, scaleFactor=1.3, minNeighbors=5)\n",
    "\n",
    "    for (x, y, w, h) in faces:\n",
    "        # Draw a rectangle around the detected face\n",
    "        cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "\n",
    "        # Analyze the person's status for 5 seconds\n",
    "        if time.time() - start_time <= analysis_duration:\n",
    "        \n",
    "            is_drunk = np.random.choice([True, False])\n",
    "\n",
    "            if is_drunk:\n",
    "                is_drunk_count += 1\n",
    "        elif not message_changed:\n",
    "            # After 5 seconds, make a decision based on the analysis\n",
    "            print(\"Analysis complete. Analyzed frames:\", is_drunk_count)\n",
    "            if is_drunk_count > 2:  # You can adjust this threshold based on your analysis\n",
    "                current_message = \"Person is not Drunk!\"\n",
    "            else:\n",
    "                current_message = \"Person is  Drunk!\"\n",
    "\n",
    "            # Add your code for actions when the decision is made\n",
    "            log_entry = f\"{datetime.datetime.now()} - {current_message}\"\n",
    "            print(log_entry)\n",
    "            log_file.write(log_entry + \"\\n\")\n",
    "\n",
    "            \n",
    "            # Set the flag to True, indicating the message has changed\n",
    "            message_changed = True\n",
    "\n",
    "    # Display the message on the frameq\n",
    "    cv2.putText(frame, current_message, (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n",
    "\n",
    "    # Display the frame\n",
    "    cv2.imshow('Drunk Detection', frame)\n",
    "\n",
    "    # Break the loop if 'q' key is pressed\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release the camera, close the log file, and close all windows\n",
    "cap.release()\n",
    "log_file.close()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "49850398-142f-4471-881f-83a246133ab7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Person is not drunk! Displaying not drunk message.\n",
      "Person is not drunk! Displaying not drunk message.\n",
      "Person is not drunk! Displaying not drunk message.\n",
      "Person is not drunk! Displaying not drunk message.\n",
      "Person is not drunk! Displaying not drunk message.\n",
      "Person is not drunk! Displaying not drunk message.\n",
      "Person is not drunk! Displaying not drunk message.\n",
      "Person is not drunk! Displaying not drunk message.\n",
      "Person is not drunk! Displaying not drunk message.\n",
      "Person is not drunk! Displaying not drunk message.\n",
      "Person is not drunk! Displaying not drunk message.\n",
      "Person is not drunk! Displaying not drunk message.\n",
      "Person is not drunk! Displaying not drunk message.\n",
      "Person is not drunk! Displaying not drunk message.\n",
      "Person is not drunk! Displaying not drunk message.\n",
      "Person is not drunk! Displaying not drunk message.\n",
      "Person is not drunk! Displaying not drunk message.\n",
      "Person is not drunk! Displaying not drunk message.\n",
      "Person is not drunk! Displaying not drunk message.\n",
      "Person is not drunk! Displaying not drunk message.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Load the pre-trained Haarcascades face classifier\n",
    "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "\n",
    "# Open the camera\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    # Read a frame from the camera\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    # Convert the frame to grayscale for face detection\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Detect faces in the frame\n",
    "    faces = face_cascade.detectMultiScale(gray, scaleFactor=1.3, minNeighbors=5)\n",
    "\n",
    "    for (x, y, w, h) in faces:\n",
    "        # Draw a rectangle around the detected face\n",
    "        cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "\n",
    "        \n",
    "        is_drunk = np.random.choice([True, False])\n",
    "\n",
    "        if not is_drunk:\n",
    "            print(\"Person is not drunk! Displaying not drunk message.\")\n",
    "            # Display a message on the frame\n",
    "            cv2.putText(frame, \"Person is Not Drunk!\", (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n",
    "\n",
    "            # Add your code for other actions when the person is not drunk\n",
    "\n",
    "    # Display the frame\n",
    "    cv2.imshow('Drunk Detection', frame)\n",
    "\n",
    "    # Break the loop if 'q' key is pressed\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release the camera and close all windows\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f578e4f1-48ac-492f-abeb-629037e7acd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: mtcnn in c:\\users\\gururaj\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (0.1.1)\n",
      "Requirement already satisfied: keras>=2.0.0 in c:\\users\\gururaj\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from mtcnn) (2.15.0)\n",
      "Requirement already satisfied: opencv-python>=4.1.0 in c:\\users\\gururaj\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from mtcnn) (4.9.0.80)\n",
      "Requirement already satisfied: numpy>=1.21.2 in c:\\users\\gururaj\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from opencv-python>=4.1.0->mtcnn) (1.26.3)\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pkg_resources'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m get_ipython()\u001b[38;5;241m.\u001b[39msystem(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpip install mtcnn\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmtcnn\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m MTCNN\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcv2\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m \n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\mtcnn\\__init__.py:26\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#!/usr/bin/python3\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# -*- coding: utf-8 -*-\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;66;03m# OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\u001b[39;00m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;66;03m# SOFTWARE.\u001b[39;00m\n\u001b[1;32m---> 26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmtcnn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmtcnn\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m MTCNN\n\u001b[0;32m     29\u001b[0m __author__ \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIvÃ¡n de Paz Centeno\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     30\u001b[0m __version__\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m0.1.0\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\mtcnn\\mtcnn.py:34\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcv2\u001b[39;00m\n\u001b[0;32m     33\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m---> 34\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpkg_resources\u001b[39;00m\n\u001b[0;32m     36\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmtcnn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexceptions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m InvalidImage\n\u001b[0;32m     37\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmtcnn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnetwork\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfactory\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m NetworkFactory\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'pkg_resources'"
     ]
    }
   ],
   "source": [
    "!pip install mtcnn\n",
    "from mtcnn import MTCNN\n",
    "import cv2\n",
    "import os \n",
    "def crop_image(source_dir, dest_dir, mode):\n",
    "    if os.path.isdir(dest_dir)==False:\n",
    "        os.mkdir(dest_dir)\n",
    "    detector = MTCNN()\n",
    "    source_list=os.listdir(source_dir)\n",
    "    uncropped_file_list=[]\n",
    "    for f in source_list:\n",
    "        f_path=os.path.join(source_dir, f)\n",
    "        dest_path=os.path.join(dest_dir,f)\n",
    "        img=cv2.imread(f_path)\n",
    "        data=detector.detect_faces(img)\n",
    "        if data ==[]:\n",
    "            uncropped_file_list.append(f_path)\n",
    "        else:\n",
    "            if mode==1:  #detect the box with the largest area\n",
    "                for i, faces in enumerate(data): # iterate through all the faces found\n",
    "                    box=faces['box']  # get the box for each face                \n",
    "                    biggest=0                    \n",
    "                    area = box[3]  * box[2]\n",
    "                    if area>biggest:\n",
    "                        biggest=area\n",
    "                        bbox=box \n",
    "                bbox[0]= 0 if bbox[0]<0 else bbox[0]\n",
    "                bbox[1]= 0 if bbox[1]<0 else bbox[1]\n",
    "                img=img[bbox[1]: bbox[1]+bbox[3],bbox[0]: bbox[0]+ bbox[2]] \n",
    "                cv2.imwrite(dest_path, img)\n",
    "            else:\n",
    "                for i, faces in enumerate(data): # iterate through all the faces found\n",
    "                    box=faces['box']\n",
    "                    if box !=[]:\n",
    "                        # return all faces found in the image\n",
    "                        box[0]= 0 if box[0]<0 else box[0]\n",
    "                        box[1]= 0 if box[1]<0 else box[1]\n",
    "                        cropped_img=img[box[1]: box[1]+box[3],box[0]: box[0]+ box[2]]\n",
    "                        fname=os.path.splitext(f)[0]\n",
    "                        fext=os.path.splitext(f)[1]\n",
    "                        fname=fname + str(i) + fext\n",
    "                        save_path=os.path.join(dest_dir,fname )\n",
    "                        cv2.imwrite(save_path, cropped_img)  \n",
    "       \n",
    "    return uncropped_file_list\n",
    "    source_directory = \"path/to/source/directory\"\n",
    "destination_directory = \"path/to/destination/directory\"\n",
    "uncropped_files = crop_image(source_directory, destination_directory, mode=1)\n",
    "print(\"Uncropped Files:\", uncropped_files)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "550c622f-7a56-4c0c-aa12-0e4bc798c52f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import datetime\n",
    "import time\n",
    "\n",
    "# Load the pre-trained Haarcascades face classifier\n",
    "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "\n",
    "# Open the camera\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Log file for recording events\n",
    "log_file = open(\"drunk_detection_log.txt\", \"a\")\n",
    "\n",
    "# Set initial message variables\n",
    "current_message = \"Initializing...\"\n",
    "message_changed = False\n",
    "\n",
    "# Variables for analyzing the person for 5 seconds\n",
    "start_time = time.time()\n",
    "analysis_duration = 5  # seconds\n",
    "is_drunk_count = 0\n",
    "\n",
    "while True:\n",
    "    # Read a frame from the camera\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    # Convert the frame to grayscale for face detection\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Detect faces in the frame\n",
    "    faces = face_cascade.detectMultiScale(gray, scaleFactor=1.3, minNeighbors=5)\n",
    "\n",
    "    for (x, y, w, h) in faces:\n",
    "        # Draw a rectangle around the detected face\n",
    "        cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "\n",
    "        # Analyze the person's status for 5 seconds\n",
    "        if time.time() - start_time <= analysis_duration:\n",
    "        \n",
    "            is_drunk = np.random.choice([True, False])\n",
    "\n",
    "            if is_drunk:\n",
    "                is_drunk_count += 1\n",
    "        elif not message_changed:\n",
    "            # After 5 seconds, make a decision based on the analysis\n",
    "            print(\"Analysis complete. Analyzed frames:\", is_drunk_count)\n",
    "            if is_drunk_count > 2:  # You can adjust this threshold based on your analysis\n",
    "                current_message = \"Person is not Drunk!\"\n",
    "            else:\n",
    "                current_message = \"Person is  Drunk!\"\n",
    "\n",
    "            # Add your code for actions when the decision is made\n",
    "            log_entry = f\"{datetime.datetime.now()} - {current_message}\"\n",
    "            print(log_entry)\n",
    "            log_file.write(log_entry + \"\\n\")\n",
    "\n",
    "            \n",
    "            # Set the flag to True, indicating the message has been changed\n",
    "            message_changed = True\n",
    "\n",
    "    # Display the message on the frameq\n",
    "    cv2.putText(frame, current_message, (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n",
    "\n",
    "    # Display the frame\n",
    "    cv2.imshow('Drunk Detection', frame)\n",
    "\n",
    "    # Break the loop if 'q' key is pressed\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release the camera, close the log file, and close all windows\n",
    "cap.release()\n",
    "log_file.close()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "800ac839-9fc8-475b-ac9c-cc81b55ad883",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Person is not drunk! Displaying not drunk message.\n",
      "Person is not drunk! Displaying not drunk message.\n",
      "Person is not drunk! Displaying not drunk message.\n",
      "Person is not drunk! Displaying not drunk message.\n",
      "Person is not drunk! Displaying not drunk message.\n",
      "Person is not drunk! Displaying not drunk message.\n",
      "Person is not drunk! Displaying not drunk message.\n",
      "Person is not drunk! Displaying not drunk message.\n",
      "Person is not drunk! Displaying not drunk message.\n",
      "Person is not drunk! Displaying not drunk message.\n",
      "Person is not drunk! Displaying not drunk message.\n",
      "Person is not drunk! Displaying not drunk message.\n",
      "Person is not drunk! Displaying not drunk message.\n",
      "Person is not drunk! Displaying not drunk message.\n",
      "Person is not drunk! Displaying not drunk message.\n",
      "Person is not drunk! Displaying not drunk message.\n",
      "Person is not drunk! Displaying not drunk message.\n",
      "Person is not drunk! Displaying not drunk message.\n",
      "Person is not drunk! Displaying not drunk message.\n",
      "Person is not drunk! Displaying not drunk message.\n",
      "Person is not drunk! Displaying not drunk message.\n",
      "Person is not drunk! Displaying not drunk message.\n",
      "Person is not drunk! Displaying not drunk message.\n",
      "Person is not drunk! Displaying not drunk message.\n",
      "Person is not drunk! Displaying not drunk message.\n",
      "Person is not drunk! Displaying not drunk message.\n",
      "Person is not drunk! Displaying not drunk message.\n",
      "Person is not drunk! Displaying not drunk message.\n",
      "Person is not drunk! Displaying not drunk message.\n",
      "Person is not drunk! Displaying not drunk message.\n",
      "Person is not drunk! Displaying not drunk message.\n",
      "Person is not drunk! Displaying not drunk message.\n",
      "Person is not drunk! Displaying not drunk message.\n",
      "Person is not drunk! Displaying not drunk message.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Load the pre-trained Haarcascades face classifier\n",
    "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "\n",
    "# Open the camera\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    # Read a frame from the camera\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    # Convert the frame to grayscale for face detection\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Detect faces in the frame\n",
    "    faces = face_cascade.detectMultiScale(gray, scaleFactor=1.3, minNeighbors=5)\n",
    "\n",
    "    for (x, y, w, h) in faces:\n",
    "        # Draw a rectangle around the detected face\n",
    "        cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "\n",
    "        \n",
    "        is_drunk = np.random.choice([True, False])\n",
    "\n",
    "        if not is_drunk:\n",
    "        \n",
    "            print(\"Person is not drunk! Displaying not drunk message.\")\n",
    "            # Display a message on the frame\n",
    "            cv2.putText(frame, \"Person is Not Drunk!\", (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n",
    "\n",
    "            # Add your code for other actions when the person is not drunk\n",
    "\n",
    "    # Display the frame\n",
    "    cv2.imshow('Drunk Detection', frame)\n",
    "\n",
    "    # Break the loop if 'q' key is pressed\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release the camera and close all windows\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbf10832-7e14-451d-bf67-fa5fb38925be",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
